{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmr3ycLG2ZcX"
   },
   "source": [
    "## Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0tPaU25U2c2l",
    "outputId": "bd6aab55-3f73-442c-aa49-3e70575856c6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import import_ipynb\n",
    "from importnb import Notebook\n",
    "with Notebook(): \n",
    "    import NN_HW3_sm as NN\n",
    "    import CNN_pool_class as CNN\n",
    "from tqdm import tqdm, trange, notebook\n",
    "from matplotlib import pyplot as plt\n",
    "np.seterr(all='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8daLbDTlLCJ"
   },
   "source": [
    "## Read Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nYNcdCW38-g4"
   },
   "outputs": [],
   "source": [
    "def read_data(image_dir, label_dir):\n",
    "    with open(image_dir, 'rb') as file:\n",
    "        magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        \n",
    "        buf = file.read(size * rows * cols)\n",
    "        img_data = np.frombuffer(buf, dtype=np.uint8).astype(np.float64)\n",
    "        img_data = img_data.reshape(size, 1, rows, cols)\n",
    "        img_data = img_data / 255\n",
    "        \n",
    "    \n",
    "    with open(label_dir, 'rb') as file:\n",
    "        magic, size = struct.unpack(\">II\", file.read(8))\n",
    "        \n",
    "        buf = file.read(size)\n",
    "        lab_data_tmp = np.frombuffer(buf, dtype=np.uint8).astype(np.uint16)\n",
    "        lab_data_tmp = lab_data_tmp.reshape(size)\n",
    "        \n",
    "#     print(lab_data[0:111])\n",
    "    lab_data = np.zeros((size, 10), dtype=np.uint16)\n",
    "    for i in range(size):\n",
    "        lab_data[i][ lab_data_tmp[i] ] = 1\n",
    "    \n",
    "#     print(lab_data[0:10])\n",
    "    \n",
    "    \n",
    "    return img_data.copy(), lab_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2oIA-pUo97IU",
    "outputId": "cc0534b4-3421-4733-c7cb-09c59a52f263",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(np.frombuffer(b'\\x02\\x01\\x00\\x00', dtype=np.uint16))\n",
    "train_data, train_label  = read_data('./MNIST/train-images-idx3-ubyte', './MNIST/train-labels-idx1-ubyte')\n",
    "test_data, test_label  = read_data('./MNIST/t10k-images-idx3-ubyte', './MNIST/t10k-labels-idx1-ubyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333333\n",
      "   0.68627451 0.10196078 0.65098039 1.         0.96862745 0.49803922\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      "   0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      "   0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.19215686 0.93333333 0.99215686 0.99215686 0.99215686\n",
      "   0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.98431373\n",
      "   0.36470588 0.32156863 0.32156863 0.21960784 0.15294118 0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.07058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "   0.99215686 0.99215686 0.77647059 0.71372549 0.96862745 0.94509804\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      "   0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.05490196 0.00392157 0.60392157\n",
      "   0.99215686 0.35294118 0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.54509804\n",
      "   0.99215686 0.74509804 0.00784314 0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.04313725\n",
      "   0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.1372549  0.94509804 0.88235294 0.62745098 0.42352941 0.00392157\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.31764706 0.94117647 0.99215686 0.99215686 0.46666667\n",
      "   0.09803922 0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      "   0.58823529 0.10588235 0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.0627451  0.36470588 0.98823529\n",
      "   0.99215686 0.73333333 0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.97647059\n",
      "   0.99215686 0.97647059 0.25098039 0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      "   0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.15294118 0.58039216 0.89803922 0.99215686 0.99215686 0.99215686\n",
      "   0.98039216 0.71372549 0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.09411765 0.44705882\n",
      "   0.86666667 0.99215686 0.99215686 0.99215686 0.99215686 0.78823529\n",
      "   0.30588235 0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      "   0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.07058824 0.67058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "   0.99215686 0.76470588 0.31372549 0.03529412 0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.21568627 0.6745098\n",
      "   0.88627451 0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
      "   0.52156863 0.04313725 0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.53333333 0.99215686\n",
      "   0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "print((train_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eI-4B9Dubcl"
   },
   "source": [
    "## Dataset Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-QysukoaafK5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333333\n",
      "   0.68627451 0.10196078 0.65098039 1.         0.96862745 0.49803922\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      "   0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      "   0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.19215686 0.93333333 0.99215686 0.99215686 0.99215686\n",
      "   0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.98431373\n",
      "   0.36470588 0.32156863 0.32156863 0.21960784 0.15294118 0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.07058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "   0.99215686 0.99215686 0.77647059 0.71372549 0.96862745 0.94509804\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      "   0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.05490196 0.00392157 0.60392157\n",
      "   0.99215686 0.35294118 0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.54509804\n",
      "   0.99215686 0.74509804 0.00784314 0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.04313725\n",
      "   0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.1372549  0.94509804 0.88235294 0.62745098 0.42352941 0.00392157\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.31764706 0.94117647 0.99215686 0.99215686 0.46666667\n",
      "   0.09803922 0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      "   0.58823529 0.10588235 0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.0627451  0.36470588 0.98823529\n",
      "   0.99215686 0.73333333 0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.97647059\n",
      "   0.99215686 0.97647059 0.25098039 0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      "   0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.15294118 0.58039216 0.89803922 0.99215686 0.99215686 0.99215686\n",
      "   0.98039216 0.71372549 0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.09411765 0.44705882\n",
      "   0.86666667 0.99215686 0.99215686 0.99215686 0.99215686 0.78823529\n",
      "   0.30588235 0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      "   0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.07058824 0.67058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "   0.99215686 0.76470588 0.31372549 0.03529412 0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.21568627 0.6745098\n",
      "   0.88627451 0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
      "   0.52156863 0.04313725 0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.53333333 0.99215686\n",
      "   0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]]]\n",
      "[[[0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.45490196 0.49019608\n",
      "   0.67058824 1.         1.         0.58823529 0.36470588 0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.6627451  0.99215686 0.99215686\n",
      "   0.99215686 0.99215686 0.99215686 0.99215686 0.85490196 0.11764706\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.6627451  0.99215686 0.99215686 0.99215686\n",
      "   0.83529412 0.55686275 0.69019608 0.99215686 0.99215686 0.47843137\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.20392157 0.98039216 0.99215686 0.82352941 0.1254902\n",
      "   0.04705882 0.         0.02352941 0.80784314 0.99215686 0.54901961\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.30196078 0.98431373 0.82352941 0.09803922 0.\n",
      "   0.         0.         0.47843137 0.97254902 0.99215686 0.25490196\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.12156863 0.07058824 0.         0.\n",
      "   0.         0.         0.81960784 0.99215686 0.99215686 0.25490196\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.45882353 0.96862745 0.99215686 0.77647059 0.03921569\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.29803922 0.96862745 0.99215686 0.90588235 0.24705882 0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.50196078 0.99215686 0.99215686 0.56470588 0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.69019608\n",
      "   0.96470588 0.99215686 0.62352941 0.04705882 0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.09803922 0.91764706\n",
      "   0.99215686 0.91372549 0.1372549  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.77647059 0.99215686\n",
      "   0.99215686 0.55294118 0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.30588235 0.97254902 0.99215686\n",
      "   0.74117647 0.04705882 0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.0745098  0.78431373 0.99215686 0.99215686\n",
      "   0.55294118 0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.5254902  0.99215686 0.99215686 0.67843137\n",
      "   0.04705882 0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.97254902 0.99215686 0.99215686 0.09803922\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.97254902 0.99215686 0.99215686 0.16862745\n",
      "   0.07843137 0.07843137 0.07843137 0.07843137 0.01960784 0.\n",
      "   0.01960784 0.07843137 0.07843137 0.14509804 0.58823529 0.58823529\n",
      "   0.58823529 0.57647059 0.03921569 0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.97254902 0.99215686 0.99215686 0.99215686\n",
      "   0.99215686 0.99215686 0.99215686 0.99215686 0.65882353 0.56078431\n",
      "   0.65098039 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      "   0.99215686 0.99215686 0.48235294 0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.68235294 0.99215686 0.99215686 0.99215686\n",
      "   0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      "   0.99215686 0.99215686 0.97647059 0.96862745 0.96862745 0.6627451\n",
      "   0.45882353 0.45882353 0.22352941 0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.4627451  0.48235294 0.48235294\n",
      "   0.48235294 0.65098039 0.99215686 0.99215686 0.99215686 0.60784314\n",
      "   0.48235294 0.48235294 0.16078431 0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_input(x):\n",
    "    return x\n",
    "\n",
    "ans = preprocess_input(train_data[0])\n",
    "ans1 = preprocess_input(test_data[1])\n",
    "print(ans)\n",
    "print(ans1)\n",
    "# print(train_data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def construct_model(model):\n",
    "    #### First Convolution + pooling\n",
    "    # func, d_func, last_layer, input_size, input_num, filter_size, filter_num, stride\n",
    "#     model.layer_list.append( CNN.ConvLayer(NN.Sigmoid, NN.d_Sigmoid, 1, input_size=28, input_num=1, filter_size=4, filter_num=4, stride=2, is_first=True))\n",
    "    # last_layer, input_size, input_num, filter_size, stride\n",
    "#     model.layer_list.append( CNN.AvgPooling(model.layer_list[0], input_size=13, input_num=4, filter_size=5, stride=2))   \n",
    "    \n",
    "    #### Second Convolution + pooling\n",
    "    # func, d_func, last_layer, input_size, input_num, filter_size, filter_num, stride\n",
    "#     model.layer_list.append( CNN.ConvLayer(NN.ReLU, NN.d_ReLU, model.layer_list[1], input_size=9, input_num=4, filter_size=3, filter_num=5, stride=1, is_first=False))\n",
    "    model.layer_list.append( CNN.ConvLayer(NN.ReLU, NN.d_ReLU, 1, input_size=28, input_num=1, filter_size=3, filter_num=5, stride=1, is_first=True))\n",
    "    # last_layer, input_size, input_num, filter_size, stride\n",
    "    model.layer_list.append( CNN.AvgPooling(model.layer_list[len(model.layer_list)-1], input_size=model.layer_list[len(model.layer_list)-1].get_output_size(), input_num=5, filter_size=5, stride=1, is_first=False))       \n",
    "#     model.layer_list.append( CNN.AvgPooling(1, input_size=28, input_num=1, filter_size=3, stride=1, is_first=True))       \n",
    "    \n",
    "    # last_layer, input_size, input_num\n",
    "#     model.layer_list.append( CNN.Flattening(1, input_size=28, input_num=1, is_first=False))\n",
    "    model.layer_list.append( CNN.Flattening(model.layer_list[len(model.layer_list)-1], input_size=model.layer_list[len(model.layer_list)-1].get_output_size(), input_num=5, is_first=False))\n",
    "    \n",
    "    #### First MLP\n",
    "    # func, d_func, node_num, last_layer, is_first\n",
    "#     model.layer_list.append( NN.Layer_vec(NN.ReLU, NN.d_ReLU, 100, model.layer_list[2], False) )\n",
    "    \n",
    "    #### Second MLP\n",
    "    # func, d_func, node_num, last_layer, is_first\n",
    "    model.layer_list.append( NN.Layer_vec(NN.ReLU, NN.d_ReLU, 64, model.layer_list[len(model.layer_list)-1], False) )\n",
    "    \n",
    "    #### Third MLP\n",
    "    # func, d_func, node_num, last_layer, is_first\n",
    "    model.layer_list.append( NN.Layer_vec(NN.ReLU, NN.d_ReLU, 10, model.layer_list[len(model.layer_list)-1], False) )\n",
    "    \n",
    "    #### Output Layer\n",
    "    model.layer_list.append( NN.Softmax_Output(model.layer_list[len(model.layer_list)-1]) )\n",
    "    print(model.layer_list)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<CNN_pool_class.ConvLayer object at 0x0000013C83F003C8>, <CNN_pool_class.AvgPooling object at 0x0000013C83F00390>, <CNN_pool_class.Flattening object at 0x0000013C83F00400>, <NN_HW3_sm.Layer_vec object at 0x0000013C83F00438>, <NN_HW3_sm.Layer_vec object at 0x0000013C800DF828>, <NN_HW3_sm.Softmax_Output object at 0x0000013C83F00518>]\n",
      "1 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37ca4b3beb344d880afd4cff21e9b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c43aa74ae44db6ba8093e30b3a3ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.8767066724962955 , acc =  71.90666666666668 %\n",
      "Test loss:  0.33137246061443415 , acc =  89.34 %\n",
      "\n",
      "2 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1a3e9453694f0fa269e4dd5e539fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5690233d9de4d668309dbb2c289c535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.2715977341248638 , acc =  91.92833333333333 %\n",
      "Test loss:  0.2355274306648897 , acc =  92.58999999999999 %\n",
      "\n",
      "3 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eef5eaa968949578c0ae4edeae5be4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b984acd5dd40fb8b9b614235bd11cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.21911746032103038 , acc =  93.56 %\n",
      "Test loss:  0.196928325846238 , acc =  93.85 %\n",
      "\n",
      "4 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85191ba17f654f709b9b7653b30d46ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34265feccddb4f7583f767a9560316ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.18729567797018148 , acc =  94.40666666666667 %\n",
      "Test loss:  0.16963388344182112 , acc =  94.69999999999999 %\n",
      "\n",
      "5 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09cfe8f4b3864f1b9e9e02da719fdb6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f729cf28936940088eb12a7e5ac336a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.1665620421936965 , acc =  95.02833333333334 %\n",
      "Test loss:  0.15063825946924758 , acc =  95.33 %\n",
      "\n",
      "6 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5415a9a86244080b81e5e2143282638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a11b531b0c4ef8a83d97134ce136bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.15195669489379732 , acc =  95.50333333333333 %\n",
      "Test loss:  0.14305658196216386 , acc =  95.69 %\n",
      "\n",
      "7 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86b2e76b0624a8cb8167532416736c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d594f85ad04b40da8ff721d1923342cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.141561262637856 , acc =  95.77166666666666 %\n",
      "Test loss:  0.13682878344057084 , acc =  95.86 %\n",
      "\n",
      "8 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9cd4f5fae94a7689eaa3e098fb16dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e084a72e3654eaeb44798b380948755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.13280241302496562 , acc =  96.00833333333333 %\n",
      "Test loss:  0.13103523364361164 , acc =  96.00999999999999 %\n",
      "\n",
      "9 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b0d5b81295472d9d951804b0573788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9d64f780ae4da483f62f6ab545e21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.12568415823033435 , acc =  96.22333333333334 %\n",
      "Test loss:  0.1278662851194321 , acc =  96.07 %\n",
      "\n",
      "10 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f757c55f69942c096322a70d4da0bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8a8159bb3a48f1a23476baa3674660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.11978891926339644 , acc =  96.38166666666666 %\n",
      "Test loss:  0.12383984231454401 , acc =  96.2 %\n",
      "\n",
      "11 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1950446bd7914cf9af1cd5010bb3cc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b7d99a9d19433b8e5525875856466b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  0.11471503948630843 , acc =  96.575 %\n",
      "Test loss:  0.12140329960631922 , acc =  96.3 %\n",
      "\n",
      "12 / 500 epochs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d051157ffa49b38f2d1a337f25bc0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=0.0, max=60000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6976761e0abd462da87aff29a9ff6e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##############################################################\n",
    "#                         MODEL block                        #\n",
    "##############################################################\n",
    "\n",
    "# with Notebook(): \n",
    "#     import NN_HW3_sm as NN\n",
    "# lr_rate = 0.00009\n",
    "epochs = 500\n",
    "\n",
    "lr_rate = 0.0001\n",
    "layer_nums = [20, 20, 20, 10]\n",
    "# layer_nums = [train_data.shape[1]-1, 7, 1]\n",
    "layer_input = preprocess_input(train_data[0])\n",
    "test_m = NN.Model(layer_nums, construct_model, layer_input, lr_rate)\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "output_node_w = [[]]\n",
    "output_node_w = np.array([test_m.get_output_w()])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_err_cnt = 0\n",
    "    train_error = []\n",
    "    print(epoch+1, \"/\", epochs, \"epochs\")\n",
    "    train_progress = notebook.tqdm(total=len(train_data), desc=\"Training\")\n",
    "    test_progress = notebook.tqdm(total=len(test_data), desc=\"Testing\")\n",
    "    for i, input_data in enumerate(train_data):\n",
    "#     for i, input_data in enumerate(train_data[0:100]):\n",
    "#         print(i, \"'s data !!!\")\n",
    "#         print(input_data)\n",
    "        train_progress.update(1)\n",
    "        p_data = preprocess_input(input_data)\n",
    "        test_m.cal_network(p_data)\n",
    "        ans_conf = test_m.get_result()\n",
    "        ans = np.argmax(ans_conf)\n",
    "        std = np.argmax(train_label[i])\n",
    "        if ans != std:\n",
    "            train_err_cnt += 1\n",
    "        \n",
    "        # Adjust model weights\n",
    "        p_loss = test_m.adjust_model(train_label[i])\n",
    "#         print(p_loss)\n",
    "        train_error.append(p_loss)\n",
    "#         print(\"ans_conf:　\", ans_conf, \"ans: \", ans, \"train_label[i]:　\", train_label[i], \"std: \", std, \"p_loss: \", p_loss)\n",
    "#         print(test_m.get_output_w())\n",
    "    output_node_w = np.append(output_node_w, [test_m.get_output_w()], 0)\n",
    "        \n",
    "    train_loss.append(np.average(train_error))\n",
    "    train_acc.append(1 - train_err_cnt/len(train_data) )\n",
    "    print(\"Train loss: \", np.average(train_error), \", acc = \", (1-train_err_cnt/len(train_data)) * 100, \"%\")\n",
    "    test_err_cnt = 0\n",
    "    test_error = []\n",
    "    for i, input_data in enumerate(test_data):\n",
    "#     for i, input_data in enumerate(test_data[0:10]):\n",
    "        # print(i, \"'s data !!!\")\n",
    "        test_progress.update(1)\n",
    "        \n",
    "        p_data = preprocess_input(input_data)\n",
    "        test_m.cal_network(p_data)\n",
    "        ans_conf = test_m.get_result()\n",
    "        ans = np.argmax(ans_conf)\n",
    "        std = np.argmax(test_label[i])\n",
    "        if ans != std:\n",
    "            test_err_cnt += 1\n",
    "        \n",
    "        \n",
    "        p_loss = test_m.get_loss(test_label[i])\n",
    "        test_error.append(p_loss)\n",
    "        \n",
    "        \n",
    "    test_loss.append(np.average(test_error))\n",
    "    test_acc.append(1 - test_err_cnt/len(test_data) )\n",
    "    print(\"Test loss: \", np.average(test_error), \", acc = \", (1-test_err_cnt/len(test_data)) * 100, \"%\")\n",
    "    print()\n",
    "test_m.get_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train loss: \", (train_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "# print(output_node_w)\n",
    "x= np.arange(0,len(output_node_w))\n",
    "fig = plt.figure(figsize=(8,12))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x, output_node_w[:,:,0])\n",
    "plt.title('Weight Change')\n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.ylabel(\"value\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "x= np.arange(0,len(train_acc))\n",
    "fig = plt.figure(figsize=(8,12))\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x, train_acc, color='Blue', label='Train')\n",
    "plt.plot(x, test_acc, color='Orange', label='Validation')\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.ylabel(\"Accuracy\") \n",
    "\n",
    "plt.legend(loc='upper left', shadow=True) \n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(x, train_loss, color='Blue', label='Train')\n",
    "plt.plot(x, test_loss, color='Orange', label='Validation')\n",
    "plt.title('Model loss')\n",
    "plt.xlabel(\"Epoch\") \n",
    "plt.ylabel(\"Loss\") \n",
    "\n",
    "plt.legend(loc='upper left', shadow=True) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0eI-4B9Dubcl"
   ],
   "name": "HW3_Q1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
